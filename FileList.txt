Markoff_2.0/
│
├── config/                          # Все конфигурации проекта (общие + per-сервис)
│   ├── .env                         # Секреты: DB_URL, API_SECRET, MODEL_PATHS, etc.
│   ├── backend.env                  # Только для backend (если разделяем .env)
│   ├── nanobot_config.json          # Конфиг Nanobot: providers, channels, temperature, max_iterations…
│   └── logging.yaml                 # Общий logging конфиг (yaml для dictConfig)
│
├── backend/                         # API-сервер + бизнес-логика + доступ к БД (самый критичный слой)
│   ├── src/
│   │   ├── __init__.py
│   │   ├── main.py                  # uvicorn entrypoint: app = FastAPI(); if __name__ == "__main__": uvicorn.run…
│   │   ├── api/
│   │   │   ├── routers/
│   │   │   │   ├── buildings.py     # Эндпоинты: /buildings, /floors, /rooms
│   │   │   │   ├── tenants.py       # /tenants, /leases, /placements
│   │   │   │   ├── sensors.py       # /sensors, /statuses, /events (POST update вручную)
│   │   │   │   └── health.py        # /health, /ready для readiness/liveness
│   │   │   └── dependencies.py      # common: get_current_user, get_db, rate_limit…
│   │   ├── db/
│   │   │   ├── models/              # SQLAlchemy declarative_base модели
│   │   │   │   ├── building.py
│   │   │   │   ├── tenant.py
│   │   │   │   └── sensor.py
│   │   │   ├── crud/                # Create / Read / Update / Delete функции
│   │   │   ├── migrations/          # alembic: versions/
│   │   │   └── session.py           # get_db generator
│   │   └── utils/
│   │       ├── visualization.py     # Pillow → генерация планов этажей (возвращает bytes)
│   │       └── helpers.py           # dt utils, enums, validators
│   └── requirements.txt             # fastapi, uvicorn, sqlalchemy, alembic, pydantic, pillow…
│
├── nanobot/                         # Локальный AI-агент (на базе nanobot-ai / HKUDS/nanobot стиля)
│   ├── src/
│   │   ├── main.py                  # nanobot gateway: load config, start channels loop
│   │   ├── agent.py                 # основной loop: plan → tool calls → execute → respond
│   │   ├── providers/               # LLM провайдеры (локальные)
│   │   │   └── vllm_local.py        # vLLM клиент на localhost:8000/v1 (OpenAI compatible)
│   │   ├── skills/                  # Навыки / tools агента
│   │   │   ├── api_bridge.py        # Вызовы backend API (httpx с auth)
│   │   │   ├── visualize_plan.py    # Запрос схемы этажа → вызов backend → TTS если нужно
│   │   │   └── status_report.py     # Агрегация тревог датчиков, etc.
│   │   ├── channels/
│   │   │   ├── telegram.py          # Telegram бот (aiogram или python-telegram-bot)
│   │   │   └── voice_processor.py   # Локальный STT + TTS пайплайн
│   │   └── stt_tts/
│   │       ├── stt.py               # faster-whisper large-v3 (cuda)
│   │       └── tts.py               # XTTS-v2 или Piper (cuda или cpu fallback)
│   └── requirements.txt             # nanobot-ai (если форк/пакет), faster-whisper, TTS (coqui), torch, torchaudio, httpx…
│
├── shared/                          # Общие типы и контракты между backend и nanobot
│   ├── schemas/                     # Pydantic модели (API request/response)
│   │   ├── building.py
│   │   ├── tenant.py
│   │   └── sensor.py
│   └── enums.py                     # StatusEnum, SensorTypeEnum, RoleEnum…
│
├── docker/
│   ├── environments/
│   │   ├── dev-compose.yml          # hot-reload, debug, без GPU
│   │   ├── prod-compose.yml         # минималистичный, restart: unless-stopped
│   │   └── gpu-compose.yml          # nvidia runtime, vLLM + STT/TTS на GPU
│   ├── monitoring/
│   │   ├── prometheus.yml
│   │   └── grafana/provisioning/    # datasources, dashboards (GPU, API latency, query count…)
│   ├── init-scripts/
│   │   ├── wait-for-postgres.sh
│   │   ├── init-db.sql              # CREATE SCHEMA security, physical, business, fire…
│   │   └── preload-models.sh        # optional: pull whisper, XTTS модели заранее
│   ├── Dockerfile.backend           # python:3.12-slim + deps без GPU
│   ├── Dockerfile.nanobot           # nvidia/cuda:12.8 + torch + vllm + faster-whisper + TTS
│   └── nginx.conf                   # reverse proxy → backend:8000, nanobot если нужен внешний канал
│
├── tests/
│   ├── backend/                     # pytest на API, crud, schemas validation
│   ├── nanobot/                     # тесты навыков, voice roundtrip (mock STT/TTS)
│   └── integration/                 # end-to-end: telegram mock → agent → api → db
│
├── docs/
│   ├── architecture.md              # общая схема, ключевой цикл, потоки
│   ├── module-import-diagram.md     # mermaid диаграмма импортов
│   ├── api-openapi.md               # или swagger export
│   ├── db-schema.md                 # ER-диаграмма или описание таблиц
│   └── local-ai-stack.md            # настройка vLLM / faster-whisper / XTTS
│
├── scripts/
│   ├── setup.sh                     # pip install -r …, alembic upgrade, nanobot onboard (если нужно)
│   ├── migrate.sh                   # alembic upgrade head
│   ├── run-backend.sh               # uvicorn backend.src.main:app --reload
│   ├── run-nanobot.sh               # python nanobot/src/main.py
│   └── start-gpu.sh                 # docker compose -f gpu-compose.yml up -d
│
├── .gitignore
├── pyproject.toml                   # poetry / uv / hatch (опционально вместо requirements)
└── README.md                        # установка, запуск, стек, как добавить навык / канал

Краткие комментарии к основным блокам
config/
Хранит всё, что можно менять без перекомпиляции: секреты, LLM параметры, API ключи (если будут гибридные), пути к моделям.
backend/
Единственный компонент, имеющий доступ к PostgreSQL. Содержит всю бизнес-логику, валидацию, авторизацию, аудит. Nanobot — просто «умный клиент» этого API.
nanobot/
Интеллектуальный слой. Обрабатывает естественный язык, голос, планирование, вызовы инструментов. Работает локально (vLLM + STT + TTS). Не имеет прямого доступа к БД — только HTTP к backend.
shared/
Контракт между сервисами. Изменение схемы здесь — сигнал, что нужно обновить и backend, и nanobot.
docker/
Всё для деплоя. Три compose-файла позволяют запускать:
• dev — быстро и просто
• prod — надёжно
• gpu — максимально быстро
tests/
Покрытие критично: backend (данные не потеряются), nanobot (агент не сломается после смены модели), интеграция (голос → текст → план → API → голос).

