### **Логика работы системы "Цифровой двойник с голосовым ассистентом"**

Вот как всё происходит от начала и до конца.

---

### **1. Загрузка и подготовка**
*   **База данных (PostgreSQL)** — это долговременная память системы. В ней навсегда записано: схема всех корпусов, списки помещений, договоры арендаторов, каталог датчиков и вся история их проверок.
*   **Кэш (Redis)** — это оперативная память. При старте или по первому запросу, самые горячие данные (например, **текущая карта статусов всех датчиков** или схема главного корпуса) загружаются сюда. Это нужно, чтобы не "дергать" тяжелую базу при каждом клике по карте.
*   **Сервисы (Estate, Tenant, Sensor)** — это "исполнительные отделы". Они просыпаются, подключаются к своей базе и кэшу, и ждут входящих заказов (запросов по API).
*   **ИИ-ядро (AI Model Server)** — самый "тяжелый" сотрудник. На сервере с видеокартой загружается большая языковая модель. Она загружает в свою контекстную память "инструкцию" (промпт), где описано: "Ты — ассистент по управлению комплексом. Ты умеешь работать с арендаторами, помещениями и датчиками. Вот структура данных...".

**Система готова. Все ждут запроса от пользователя.**

---

### **2. Пользователь делает запрос (Сценарий 1: Голос через Telegram)**
Сотрудник охраны, обходя здание, нажимает в Telegram-боте кнопку "Голосовое сообщение" и говорит: *"Покажи все неисправные датчики в корпусе А"*.

1.  **Приём и маршрутизация:**
    *   Telegram-бот (это просто "телефонный аппарат") получает аудиофайл.
    *   Бот не разбирается в содержании. Он просто упаковывает файл и данные пользователя и отправляет **запрос на общий входной шлюз (API Gateway)** по адресу `/ai/voice`.
    *   Шлюз проверяет: "А имеет ли этот пользователь право что-то спрашивать?". Проверяет токен. Если всё ок — пропускает запрос дальше, в **ядро ИИ-ассистента**.

2.  **Понимание намерения (Магия ИИ):**
    *   **Шаг А: "Услышать".** Специальный модуль преобразует голос в текст. Получается строка: *"Покажи все неисправные датчики в корпусе А"*.
    *   **Шаг Б: "Понять".** Этот текст попадает в большую языковую модель (LLM на RTX 5090). Модель, обученная на вашей специфике, анализирует фразу:
        *   **Намерение (Intent):** `сгенерировать_отчет` или `получить_данные`.
        *   **Сущности (Entities):** `объект: датчики`, `статус: неисправны`, `локация: корпус А`.
    *   **Шаг В: "Составить план".** ИИ-оркестратор понимает: "Ага, пользователю нужен отчет. Чтобы его сделать, мне нужно: 1) Узнать ID корпуса с названием 'А'. 2) Запросить все датчики с этим ID корпуса и статусом 'Неисправен'. 3) Оформить ответ".
    *   **Шаг Г: "Найти инструменты".** Внутренний "диспетчер" ИИ знает, что за данные о корпусах отвечает `Estate Service`, а за статусы датчиков — `Sensor Service`. Он готовится сделать к ним запросы.

3.  **Выполнение плана (Работа с ядром логики):**
    *   **Запрос 1:** ИИ-ядро (от имени пользователя) отправляет запрос к **Estate Service**: "Дай мне ID корпуса с названием 'А'".
    *   **Сервис недвижимости** идет в кэш (быстро) или в базу (медленнее), находит запись и возвращает ID, например, `building_id: 1`.
    *   **Запрос 2:** ИИ-ядро отправляет запрос к **Sensor Status Service**: "Дай мне все датчики с `building_id=1` и `status='Неисправен'`".
    *   **Сервис датчиков** выполняет сложный запрос в базу (через связи: датчик -> помещение -> этаж -> корпус), фильтрует по статусу и возвращает структурированный список: `[{"id": 501, "room": "А-101"}, {"id": 512, "room": "А-202"}]`.

4.  **Формирование и доставка ответа:**
    *   **Шаг А: "Объяснить".** ИИ-ядро получает "сырые" данные от сервисов. LLM получает задачу: "Вот данные для пользователя. Сформируй ясный, краткий, устный ответ". Модель генерирует текст: *"В корпусе А обнаружено 2 неисправных датчика: датчик №501 в помещении А-101 и датчик №512 в А-202. Рекомендуется направить техника для проверки."*
    *   **Шаг Б: "Озвучить" (опционально).** Если бот поддерживает голосовые ответы, текст отправляется в модуль синтеза речи (TTS), который создает аудиофайл.
    *   **Шаг В: "Отправить".** ИИ-ядро возвращает готовый ответ (текст + возможно аудио) через API Gateway обратно Telegram-боту.
    *   **Бот** просто показывает текст или проигрывает голосовое сообщение сотруднику.

**Весь этот путь, от голосового сообщения до ответа, занимает секунды.**

---

### **3. Пользователь делает запрос (Сценарий 2: Действие через десктоп)**
Менеджер в своем кабинете видит на интерактивной карте в десктопном приложении, что датчик в комнате "Б-305" горит красным (статус "Неисправен"). Он кликает на него, выбирает в контекстном меню "Изменить статус" -> "Исправен" и нажимает "Сохранить".

1.  **Приём действия:**
    *   Десктоп-приложение (это "пульт управления") не спрашивает ИИ. Оно знает, что для изменения статуса нужно отправить конкретный API-запрос.
    *   Приложение формирует команду: `PUT /api/sensors/705/status` с телом `{"new_status": "Исправен", "comment": "Замена батареи", "changed_by": "Иванов"}`.
    *   Запрос отправляется через **API Gateway**.
    *   Может отслать запрос к ИИ**.

2.  **Выполнение команды (Только Services Layer):**
    *   Шлюз видит путь `/api/sensors/...` и перенаправляет запрос прямиком в **Sensor Status Service**.
    *   **Сервис датчиков** получает запрос. Это его единственная и главная обязанность. Он выполняет критически важную последовательность:
        *   Проверяет права пользователя "Иванов" на изменение датчиков.
        *   **Внутри одной транзакции в базе данных:**
            *   Обновляет поле `status` у датчика с ID 705 на "Исправен".
            *   **Создает новую запись в таблице `sensor_status_history`** (кто, когда, какой статус выставил, комментарий). Это аудит-лог, его нельзя потерять.
        *   **Отправляет событие в кэш (Redis):** "Данные по датчику 705 устарели!". Система кэширования обновляет карту статусов.
        *   Возвращает приложению ответ: "Статус успешно обновлен".

3.  **Мгновенная синхронизация интерфейсов:**
    *   **Десктоп-приложение** получает ответ и мгновенно перекрашивает иконку датчика 705 с красного на зеленый.
    *   **Телеграм-бот и другие клиенты** ничего не знают об этом изменении, пока не запросят данные заново. Но если бы у них была открыта "живая" карта с подпиской на обновления (через WebSockets), они бы тоже увидели изменение в реальном времени.

---

### **4. Связь блоков и поток данных: ключевые принципы**

1.  **ИИ — это "умный консультант", а не "исполнитель".** Он только переводит запрос с человеческого языка на машинный, получает данные и красиво их подает. Все изменения в системе (смена статуса, заключение договора) происходят **только** через прямые вызовы соответствующих сервисов.
2.  **Сервисы — "единственные источники правды".** За состояние датчиков отвечает только `Sensor Status Service`. Если ИИ захочет сменить статус, он не сделает это сам, а **скажет менеджеру**: "Чтобы сменить статус, нажмите такую-то кнопку", или (в продвинутой версии) сам вызовет API этого сервиса, но только если у него есть на это явные права.
3.  **Данные текут сверху вниз.** Пользовательский запрос спускается через слои, пока не доходит до "исполнителей" (сервисов), которые работают с памятью (БД, кэш).
4.  **Ответ течёт снизу вверх.** "Сырые" данные из БД поднимаются в сервисы, там структурируются, затем попадают в ИИ для "очеловечивания" или сразу в UI для отображения.
5.  **Изменение в одном месте = обновление для всех.** Благодаря общему кэшу и четким API, изменение, сделанное через десктоп, становится мгновенно доступным для ИИ-ассистента и наоборот. Пользователь в Telegram может спросить: *"Какой сейчас статус датчика в 305?"* и получит уже актуальный ответ: *"Исправен"*.

**Итог:** Система работает как слаженный механизм, где каждый блок делает своё дело. **ИИ-ассистент** делает систему доступной и интуитивной через речь и текст. **Сервисы** обеспечивают надёжность и точность бизнес-логики. **База и кэш** хранят правду. А **UI и боты** дают удобный доступ в любом месте и с любого устройства.
